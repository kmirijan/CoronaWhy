{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, json\n",
    "\n",
    "from os import listdir\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = 'data'\n",
    "VERSION = 'cord19_v20'\n",
    "META_PATH =\"/\".join([DATAPATH, VERSION, 'metadata.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63571, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khachatur\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "meta_df = pd.read_csv(META_PATH)\n",
    "print(meta_df.shape)\n",
    "# meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-a53374bc6351>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-a53374bc6351>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print(\"All cuid duplicate records:\"len(cuid_dup))\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "cuid_dup = meta_df[meta_df.duplicated(['cord_uid'])]\n",
    "cuid_dup_set = set(cuid_dup['cord_uid'])\n",
    "print(\"All cuid duplicate records:\"len(cuid_dup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in cuid_dup_set:\n",
    "    dup_df = meta_df[meta_df['cord_uid'] == uid]\n",
    "    if len(dup_df['pubmed_id'].unique()) != 1 and len(dup_df['doi'].unique()) != 1:\n",
    "        print(dup_df['pubmed_id'].unique())\n",
    "        print(dup_df['doi'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_pdfpar_df = meta_df[meta_df['pdf_json_files'].isna() == False]\n",
    "pdfpar_dup = has_pdfpar_df[has_pdfpar_df.duplicated(['pdf_json_files'])]\n",
    "print(\"Duplicte pdf paths:\", len(pdfpar_dup))\n",
    "print(\"Total pdf paths\", len(has_pdfpar_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_pmcpar_df = meta_df[meta_df['pmc_json_files'].isna() == False]\n",
    "pmcpar_dup = has_pmcpar_df[has_pmcpar_df.duplicated(['pmc_json_files'])]\n",
    "print(\"Duplicte pmc paths:\", len(pmcpar_dup))\n",
    "print(\"Total pmc paths\", len(has_pmcpar_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of records with multiple associated sha values: 2517\n"
     ]
    }
   ],
   "source": [
    "has_sha_df = meta_df[meta_df['sha'].isna() == False]\n",
    "mult_sha_df = has_sha_df[has_sha_df['sha'].str.len() != 40]\n",
    "sing_sha_df = has_sha_df[has_sha_df['sha'].str.len() == 40]\n",
    "print(\"# of records with multiple associated sha values:\", len(mult_sha_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of weird pmcid values: 0\n"
     ]
    }
   ],
   "source": [
    "has_pmc_df = meta_df[meta_df['pmcid'].isna() == False]\n",
    "print(\"# of weird pmcid values:\", len(has_pmc_df[(has_pmc_df['pmcid'].str.len() != 9) & (has_pmc_df['pmcid'].str.len() != 10) & (has_pmc_df['pmcid'].str.len() != 8)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "PARSE_PATH =\"/\".join([DATAPATH, VERSION, 'document_parses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # pdfs: 33503\n",
      "Total # pmcs: 51868\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"/\".join([PARSE_PATH, 'pdf_json'])\n",
    "pmc_path = \"/\".join([PARSE_PATH, 'pmc_json'])\n",
    "pdf_parses = listdir(pdf_path)\n",
    "pmc_parses = listdir(pmc_path)\n",
    "print(\"Total # pdfs:\", len(pmc_parses))\n",
    "print(\"Total # pmcs:\", len(pdf_parses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sha values in multi sha record list: 5475\n",
      "All UNIQUE sha values in multi sha record list: 5475\n",
      "All sha values in single sha record list: 46407\n",
      "All UNIQUE sha values in single sha record list: 46394\n",
      "All sha values in combined sha record list: 51882\n",
      "All UNIQUE sha values in combined sha record list: 51868\n"
     ]
    }
   ],
   "source": [
    "sha_list = []\n",
    "for row in mult_sha_df.iterrows():\n",
    "    new_l = row[1].sha.split(\"; \")\n",
    "    sha_list.extend(new_l)\n",
    "print(\"All sha values in multi sha record list:\", len(sha_list))\n",
    "print(\"All UNIQUE sha values in multi sha record list:\", len(set(sha_list)))\n",
    "\n",
    "print(\"All sha values in single sha record list:\", len(list(sing_sha_df.sha)))\n",
    "print(\"All UNIQUE sha values in single sha record list:\", len(set(sing_sha_df.sha)))\n",
    "\n",
    "sha_list.extend(list(sing_sha_df.sha))\n",
    "print(\"All sha values in combined sha record list:\", len(sha_list))\n",
    "print(\"All UNIQUE sha values in combined sha record list:\", len(set(sha_list)))\n",
    "total_unique_sha = len(set(sha_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total full text records: 49862\n"
     ]
    }
   ],
   "source": [
    "has_path_df = meta_df[(meta_df[\"pdf_json_files\"].isna() == False) | (meta_df[\"pmc_json_files\"].isna() == False)]\n",
    "print(\"Total full text records:\", len(has_path_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_id = []\n",
    "errors_title = []\n",
    "for row in has_path_df.iterrows():\n",
    "    record = row[1]\n",
    "    data = None\n",
    "    if not isinstance(record.pmc_json_files, float):\n",
    "        json_paths = [\"/\".join([DATAPATH, VERSION, record.pmc_json_files])]\n",
    "        p_ids = [record.pmcid]\n",
    "    else:\n",
    "        pdf_paths = record.pdf_json_files.split(\"; \")\n",
    "        json_paths = [\"/\".join([DATAPATH, VERSION, x]) for x in pdf_paths]\n",
    "        p_ids = record.sha.split(\"; \")\n",
    "    \n",
    "    for i, path in enumerate(json_paths):\n",
    "        cur_size = len(errors_title)\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if data['paper_id'] != p_ids[i]:\n",
    "            \n",
    "            errors_id.append([data['paper_id'], p_ids[i]])\n",
    "            \n",
    "        json_title = data['metadata']['title'].lower()\n",
    "        try:\n",
    "            meta_title = record.title.lower()\n",
    "        except:\n",
    "            meta_title = ''\n",
    "        title_ratio = fuzz.ratio(meta_title, json_title)\n",
    "        partial_ratio = fuzz.partial_ratio(meta_title, json_title)\n",
    "\n",
    "        if cur_size == len(errors_title):\n",
    "            if title_ratio > 85 or partial_ratio > 85:\n",
    "                break\n",
    "            else:\n",
    "                errors_title.append([json_title, meta_title, title_ratio, partial_ratio, data['paper_id']])\n",
    "        else:\n",
    "            if title_ratio > 85 or partial_ratio > 85:\n",
    "                errors_title.pop()\n",
    "                break\n",
    "            elif title_ratio > errors_title[-1][3] or partial_ration > errors_title[-1][3]:\n",
    "                errors_title.pop()\n",
    "                errors_title.append([json_title, meta_title, title_ratio, partial_ratio, data['paper_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_json_titles = 0\n",
    "empty_meta_titles = 0\n",
    "other_errors_titles = 0\n",
    "sha_errors = 0\n",
    "pmc_errors = 0\n",
    "for error in errors_title:\n",
    "    if error[0] == '':\n",
    "        empty_json_titles += 1\n",
    "    if error[1] == '':\n",
    "        empty_meta_titles += 1\n",
    "    if error[0] != '' and error[1] !='':\n",
    "        other_errors_titles += 1\n",
    "    if len(error[4]) == 40:\n",
    "        sha_errors += 1\n",
    "    if len(error[4]) != 40:\n",
    "        pmc_errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ID errors: 0\n",
      "Discrepencies between metadata title and file title: 3547\n",
      "Empty title value in json file: 2294\n",
      "Empty title value from metadata records: 6\n",
      "All other title errors: 1247\n",
      "Errors in pdf files: 3527\n",
      "Errors in pmc files: 20\n"
     ]
    }
   ],
   "source": [
    "print(\"Total ID errors:\", len(errors_id))\n",
    "print(\"Discrepencies between metadata title and file title:\", len(errors_title))\n",
    "print(\"Empty title value in json file:\", empty_json_titles)\n",
    "print(\"Empty title value from metadata records:\", empty_meta_titles)\n",
    "print(\"All other title errors:\", other_errors_titles)\n",
    "print(\"Errors in pdf files:\", sha_errors)\n",
    "print(\"Errors in pmc files:\", pmc_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
